{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd03b1827d4b6462cc460901af0bc0d075c933010817877a813d51f78a107cbf6e5",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3b1827d4b6462cc460901af0bc0d075c933010817877a813d51f78a107cbf6e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#### Process raw words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\storage\\\\stopWords.txt'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3248b43c0653>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'..\\storage\\stopWords.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m      \u001b[0msplitted_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m      \u001b[0mproc_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplitted_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'..\\storage\\stop_words.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\storage\\\\stopWords.txt'"
     ]
    }
   ],
   "source": [
    "# with open(r'..\\storage\\stopWords.txt', 'r') as reader:\n",
    "#      splitted_text = reader.read().split(' ')\n",
    "#      proc_text = sorted(splitted_text)\n",
    "\n",
    "# with open(r'..\\storage\\stop_words.txt', 'w') as writer:\n",
    "#      for word in proc_text:\n",
    "#        writer.write(word+'\\n')"
   ]
  },
  {
   "source": [
    "### Convert to tries"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENT_VALUE_KEY = '___'\n",
    "TRIE_JSON_FILE = r'..\\storage\\compressed_trie.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1419\n4548\n759\n"
     ]
    }
   ],
   "source": [
    "# read postive words list from file\n",
    "pos_words = []\n",
    "with open(r'..\\storage\\pos_words.txt', 'r') as reader:\n",
    "    pos_words = sorted(reader.read().split('\\n'))\n",
    "print(len(pos_words))\n",
    "\n",
    "# read negative words list from file\n",
    "neg_words = []\n",
    "with open(r'..\\storage\\neg_words.txt', 'r') as reader:\n",
    "    neg_words = sorted(reader.read().split('\\n'))\n",
    "print(len(neg_words))\n",
    "\n",
    "# TODO: read stop words list from file\n",
    "stop_words = []\n",
    "with open(r'..\\storage\\stop_words.txt', 'r') as reader:\n",
    "    stop_words = sorted(reader.read().split('\\n'))\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('a reason for being', 1)\n('abnormal', -1)\n(\"'ll\", -1000)\n"
     ]
    }
   ],
   "source": [
    "# create input variable for build_tries()\n",
    "pos_values = [1] * len(pos_words)\n",
    "pos_words_values = list(zip(pos_words, pos_values)) # [('a reason for being', 1), ('able', 1), ()]\n",
    "print(pos_words_values[0])\n",
    "\n",
    "neg_values = [-1] * len(neg_words)\n",
    "neg_words_values = list(zip(neg_words, neg_values))\n",
    "print(neg_words_values[0])\n",
    "\n",
    "# TODO: create input variable for stop words\n",
    "stop_values = [-1000] * len(stop_words)\n",
    "stop_words_values = list(zip(stop_words, stop_values))\n",
    "print(stop_words_values[0])\n",
    "\n",
    "words_values = stop_words_values + pos_words_values + neg_words_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n    \"'\": {\n        \"l\": {\n            \"l\": {\n                \"___\": -1000\n            }\n        },\n        \"v\": {\n            \"e\": {\n                \"___\": -1000\n            }\n        }\n    },\n    \"a\": {\n        \"___\": -1000,\n        \"'\": {\n            \"s\": {\n                \"___\": -1000\n            }\n        },\n        \"b\": {\n            \"l\": {\n                \"e\": {\n                    \"___\": 1\n                }\n            },\n            \"o\": {\n                \"u\": {\n                    \"t\": {\n                        \"___\": -1000\n"
     ]
    }
   ],
   "source": [
    "# build uncompressed trie\n",
    "def build_tries(words_values: list) -> dict:\n",
    "    'Creates a basic uncompressed trie from a sorted list of words with sentiment values.'\n",
    "    root = {}\n",
    "    for (word, value) in words_values:\n",
    "        node = root\n",
    "        word_len = len(word)\n",
    "        for i, char in enumerate(word):\n",
    "            # create a new child if no char found\n",
    "            if char not in node:\n",
    "                node[char] = {}\n",
    "            \n",
    "            # put a key in child indicate end of a complete word\n",
    "            if i == word_len - 1:\n",
    "                node[char][SENT_VALUE_KEY] = value\n",
    "            node = node[char]\n",
    "    return root\n",
    "\n",
    "# create uncompressed trie\n",
    "newTrie = build_tries(words_values)\n",
    "print('\\n'.join(json.dumps(newTrie, indent=4).split('\\n')[:30]))\n",
    "\n",
    "# with open(TRIE_JSON_FILE, 'w') as outfile:\n",
    "#     json.dump(newTrie, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n    \"'\": {\n        \"ll\": {\n            \"___\": -1000\n        },\n        \"ve\": {\n            \"___\": -1000\n        }\n    },\n    \"a\": {\n        \"___\": -1000,\n        \"'s\": {\n            \"___\": -1000\n        },\n        \"b\": {\n            \"le\": {\n                \"___\": 1\n            },\n            \"o\": {\n                \"u\": {\n                    \"t\": {\n                        \"___\": -1000\n                    },\n                    \"nd\": {\n                        \"___\": 1,\n                        \"ing\": {\n                            \"___\": 1\n                        },\n                        \"s\": {\n                            \"___\": 1\n"
     ]
    }
   ],
   "source": [
    "# compress the tries\n",
    "def rec_search(key: str, trie: dict) -> (str, dict):\n",
    "    # base case\n",
    "    # end of last character of complete word\n",
    "    if type(trie) is int:\n",
    "        return key[:-len(SENT_VALUE_KEY)], {SENT_VALUE_KEY:trie}\n",
    "\n",
    "    children_size = len(trie)\n",
    "    newChildren = {}\n",
    "\n",
    "    if children_size == 1:\n",
    "        for childKey, childTrie in trie.items():\n",
    "            prefixKey = key+childKey\n",
    "            newKey, newChild = rec_search(prefixKey, childTrie)\n",
    "\n",
    "            # special case\n",
    "            # if the root tree only has one children\n",
    "            if key == '':\n",
    "                return '', {newKey:newChild}\n",
    "\n",
    "            return newKey, newChild\n",
    "    else:\n",
    "        for childKey, childTrie in trie.items():\n",
    "            if childKey == SENT_VALUE_KEY:\n",
    "                newChildren[childKey] = childTrie\n",
    "            else:\n",
    "                prefixKey = ''+childKey\n",
    "                newKey, newChild = rec_search(prefixKey, childTrie)\n",
    "                newChildren[newKey] = newChild\n",
    "\n",
    "    return key, newChildren\n",
    "\n",
    "def compress_trie(trie: dict) -> dict:\n",
    "    trie = copy.deepcopy(trie)\n",
    "    _, compressedTrie = rec_search('', trie)\n",
    "    return compressedTrie\n",
    "\n",
    "# compress the trie\n",
    "cTrie = compress_trie(newTrie)\n",
    "print('\\n'.join(json.dumps(cTrie, indent=4).split('\\n')[:30]))\n",
    "\n",
    "# write to a file\n",
    "with open(TRIE_JSON_FILE, 'w') as outfile:\n",
    "    json.dump(cTrie, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "able : 1\nallow : 1\nappreciate : 1\nappropriate : 1\nawfully : -1\nbest : 1\nbetter : 1\nbeyond : 1\ncertain : 1\ndo : 1\nenough : 1\ngive : 1\ngiving : 1\nhello : 1\nhelp : 1\ninner : 1\njust : 1\nlike : 1\nmany : 1\nmiss : -1\nmore : 1\nnew : 1\nok : 1\non : 1\nplease : 1\npoorly : -1\nproud : 1\nsorry : -1\nstill : 1\nthank : 1\nunfortunately : -1\nunlikely : -1\nup : 1\nuseful : 1\nvalue : 1\nvery : 1\nwelcome : 1\nwell : 1\nwhole : 1\nwill : 1\nwilling : 1\nwonder : 1\nyes : 1\naudacity : -1\nblinding : -1\ndope : -1\nemphatic : -1\ngiddy : -1\nincomparable : -1\njoke : -1\njumpy : -1\nunbelievable : -1\nvulnerable : -1\nzealous : -1\n"
     ]
    }
   ],
   "source": [
    "# test the compressed trie\n",
    "def search(trie: dict, word: str) -> int:\n",
    "    '''\n",
    "    Helper method to search compressed trie\n",
    "    '''\n",
    "    word_length = len(word)\n",
    "    offset = 0\n",
    "    lastIndex = 0\n",
    "\n",
    "    for i in range(word_length):\n",
    "        key = word[offset:i+1]\n",
    "        value = trie.get(key)\n",
    "\n",
    "        if value is not None:\n",
    "            trie = value\n",
    "            offset += len(key)\n",
    "            lastIndex = i\n",
    "\n",
    "    result = trie.get(SENT_VALUE_KEY)\n",
    "    if result is None or lastIndex != word_length - 1:\n",
    "        return 0\n",
    "    return result\n",
    "\n",
    "# test the results \n",
    "for (word, value) in words_values:\n",
    "    sent_value = search(cTrie, word)\n",
    "    if(value != sent_value):\n",
    "        print(word, ':', sent_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}